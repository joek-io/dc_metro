name: CI - Pipeline smoke test + checks

on:
  push:
  pull_request:

jobs:
  pipeline:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", "3.11"]

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          lfs: false

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          set -e
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install pandas openpyxl pyogrio geopandas shapely pyproj
          pip install pytest flake8

      - name: Create fixture data
        run: |
          set -e
          mkdir -p data_raw data_geo results/tables data_clean

          printf '%s\n' \
            'Station,Year,Month,Time_Period,Day_Type,Entries' \
            'GALLERY PL-CHINATOWN,2019,1,AM,Weekday,100' \
            'GALLERY PL-CHINATOWN,2019,1,Midday,Weekday,80' \
            'GALLERY PL-CHINATOWN,2019,1,PM,Weekday,120' \
            'GALLERY PL-CHINATOWN,2019,1,Evening,Weekday,60' \
            'UNION STATION,2019,1,AM,Weekday,150' \
            'UNION STATION,2019,1,Midday,Weekday,90' \
            'UNION STATION,2019,1,PM,Weekday,130' \
            'UNION STATION,2019,1,Evening,Weekday,70' \
            'GALLERY PL-CHINATOWN,2019,1,AM,Weekend,40' \
            'UNION STATION,2019,1,AM,Weekend,50' \
            > data_raw/ridership_2019.csv

          printf '%s\n' \
            'Station,Year,Month,Time_Period,Day_Type,Entries' \
            'GALLERY PL-CHINATOWN,2023,1,AM,Weekday,82' \
            'GALLERY PL-CHINATOWN,2023,1,Midday,Weekday,75' \
            'UNION STATION,2023,1,AM,Weekday,140' \
            'UNION STATION,2023,1,PM,Weekday,110' \
            'GALLERY PL-CHINATOWN,2023,1,AM,Weekend,35' \
            'UNION STATION,2023,1,AM,Weekend,45' \
            > data_raw/ridership_2023_tapped.csv

          printf '%s\n' \
            'Station,Year,Month,Time_Period,Day_Type,Entries' \
            'GALLERY PL-CHINATOWN,2023,1,AM,Weekday,3' \
            'GALLERY PL-CHINATOWN,2023,1,Midday,Weekday,2' \
            'UNION STATION,2023,1,AM,Weekday,4' \
            'UNION STATION,2023,1,PM,Weekday,3' \
            'GALLERY PL-CHINATOWN,2023,1,AM,Weekend,1' \
            'UNION STATION,2023,1,AM,Weekend,2' \
            > data_raw/ridership_2023_nontapped.csv

          printf '%s\n' \
            '{' \
            '  "type": "FeatureCollection",' \
            '  "name": "metro_stations",' \
            '  "crs": { "type": "name", "properties": { "name": "EPSG:4326" } },' \
            '  "features": [' \
            '    {' \
            '      "type": "Feature",' \
            '      "properties": { "NAME": "GALLERY PL-CHINATOWN" },' \
            '      "geometry": { "type": "Point", "coordinates": [ -77.0219, 38.8983 ] }' \
            '    },' \
            '    {' \
            '      "type": "Feature",' \
            '      "properties": { "NAME": "UNION STATION" },' \
            '      "geometry": { "type": "Point", "coordinates": [ -77.0075, 38.8971 ] }' \
            '    }' \
            '  ]' \
            '}' \
            > data_geo/metro_stations.geojson

      - name: Convert CSVs to UTF-16LE
        run: |
          set -e
          for f in data_raw/*.csv; do
            [ -f "$f" ] || continue
            iconv -f UTF-8 -t UTF-16LE "$f" > "${f}.utf16le"
            mv "${f}.utf16le" "$f"
            echo "Re-encoded $f to UTF-16LE"
          done

      - name: Run 01_clean_data.py
        run: |
          set -e
          python analysis/01_clean_data.py

      - name: Verify schema
        run: |
          set -e
          python -c "import pandas as pd; df=pd.read_csv('data_clean/station_monthly_recovery.csv'); exp={'Station','Year','Month','Time_Period','Day_Type','Entries','Entries_2019','Recovery_Ratio','Denom_Flag'}; missing=exp-set(df.columns); assert not missing, 'Missing columns: %s' % (missing,); assert len(df)>0, 'Empty CSV'; print('Schema OK, rows=', len(df))"

      - name: Run 02_inference_tests.py
        run: |
          set -e
          python analysis/02_inference_tests.py

      - name: Verify inference JSON
        run: |
          set -e
          python -c "import json, pathlib; p=pathlib.Path('results/tables/stats_summary.json'); assert p.exists(), 'stats_summary.json missing'; d=json.loads(p.read_text()); assert 'status' in d, 'Missing key'; assert d.get('status') in ['ok','warning'], 'Bad status: %s' % d.get('status'); print('Inference JSON OK')"

      - name: Run 03_tableau_export.py
        run: |
          set -e
          python analysis/03_tableau_export.py

      - name: Verify Tableau export
        run: |
          set -e
          python -c "import pandas as pd; df=pd.read_csv('data_clean/tableau_recovery.csv'); assert {'Longitude','Latitude'}.issubset(df.columns), 'Missing geometry'; cov=float(df[['Longitude','Latitude']].notna().mean().mean()); assert cov>0.5, 'Low geometry coverage: %.2f' % cov; print('Tableau export OK, rows=', len(df))"

      - name: Run pytest
        run: |
          set -e
          mkdir -p tests
          echo 'def test_placeholder(): assert True' > tests/test_placeholder.py
          pytest -q

      - name: Lint (flake8, non-blocking)
        run: |
          flake8 analysis --max-line-length=100 || true

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-outputs-${{ matrix.python-version }}
          path: |
            data_clean/**
            results/tables/**
          if-no-files-found: warn
